{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary material results with all filtering basis. It takes 1 hour computation times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from time import *\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir('../../Datasets')\n",
    "\n",
    "chinatown = pd.read_csv('China_Train.csv', header = None)\n",
    "chinatown2 = pd.read_csv('China_Test.csv', header = None)\n",
    "\n",
    "\n",
    "X1_train = np.array(chinatown, dtype = float)[:,1:]\n",
    "X1_test = np.array(chinatown2, dtype = float)[:,1:]\n",
    "y1_train = np.array(chinatown, dtype=float)[:,0]\n",
    "y1_test = np.array(chinatown2, dtype=float)[:,0]\n",
    "\n",
    "coffee = pd.read_csv('Coffee_Train.csv', header = None)\n",
    "coffee2 = pd.read_csv('Coffee_Test.csv', header = None)\n",
    "\n",
    "\n",
    "X2_train = np.array(coffee, dtype = float)[:,1:]\n",
    "X2_test = np.array(coffee2, dtype = float)[:,1:]\n",
    "y2_train = np.array(coffee, dtype=float)[:,0]\n",
    "y2_test = np.array(coffee2, dtype=float)[:,0]\n",
    "\n",
    "ecgfivedays = pd.read_csv('ECGFiveDays_Train.csv', header = None)\n",
    "ecgfivedays2 = pd.read_csv('ECGFiveDays_Test.csv', header = None)\n",
    "\n",
    "\n",
    "X3_train = np.array(ecgfivedays, dtype = float)[:,1:]\n",
    "X3_test = np.array(ecgfivedays2, dtype = float)[:,1:]\n",
    "y3_train = np.array(ecgfivedays, dtype=float)[:,0]\n",
    "y3_test = np.array(ecgfivedays2, dtype=float)[:,0]\n",
    "\n",
    "ecg200 = pd.read_csv('ECG200_Train.csv', header = None)\n",
    "ecg200_2 = pd.read_csv('ECG200_Test.csv', header = None)\n",
    "\n",
    "\n",
    "X4_train = np.array(ecg200, dtype = float)[:,1:]\n",
    "X4_test = np.array(ecg200_2, dtype = float)[:,1:]\n",
    "y4_train = np.array(ecg200, dtype=float)[:,0]\n",
    "y4_test = np.array(ecg200_2, dtype=float)[:,0]\n",
    "\n",
    "handoutlines = pd.read_csv('Handoutlines_Train.csv', header = None)\n",
    "handoutlines_2 = pd.read_csv('Handoutlines_Test.csv', header = None)\n",
    "\n",
    "\n",
    "X5_train = np.array(handoutlines, dtype = float)[:,1:]\n",
    "X5_test = np.array(handoutlines_2, dtype = float)[:,1:]\n",
    "y5_train = np.array(handoutlines, dtype=float)[:,0]\n",
    "y5_test = np.array(handoutlines_2, dtype=float)[:,0]\n",
    "\n",
    "SonyRobotAI1 = pd.read_csv('SonyRobotAI1_Train.csv', header = None)\n",
    "SonyRobotAI1_2 = pd.read_csv('SonyRobotAI1_Test.csv', header = None)\n",
    "\n",
    "\n",
    "X6_train = np.array(SonyRobotAI1, dtype = float)[:,1:]\n",
    "X6_test = np.array(SonyRobotAI1_2, dtype = float)[:,1:]\n",
    "y6_train = np.array(SonyRobotAI1, dtype=float)[:,0]\n",
    "y6_test = np.array(SonyRobotAI1_2, dtype=float)[:,0]\n",
    "\n",
    "\n",
    "SonyRobotAI2 = pd.read_csv('SonyRobotAI2_Train.csv', header = None)\n",
    "SonyRobotAI2_2 = pd.read_csv('SonyRobotAI2_Test.csv', header = None)\n",
    "\n",
    "\n",
    "X7_train = np.array(SonyRobotAI2, dtype = float)[:,1:]\n",
    "X7_test = np.array(SonyRobotAI2_2, dtype = float)[:,1:]\n",
    "y7_train = np.array(SonyRobotAI2, dtype=float)[:,0]\n",
    "y7_test = np.array(SonyRobotAI2_2, dtype=float)[:,0]\n",
    "\n",
    "\n",
    "starlightcurves = pd.read_csv('StarLightCurves_Train.csv', header = None)\n",
    "starlightcurves2  = pd.read_csv('StarLightCurves_Test1.csv', header = None)\n",
    "starlightcurves3  = pd.read_csv('StarLightCurves_Test2.csv', header = None)\n",
    "\n",
    "\n",
    "X8_train = np.array(starlightcurves, dtype = float)[:,1:]\n",
    "y8_train = np.array(starlightcurves, dtype=float)[:,0]\n",
    "\n",
    "X8_test1 = np.array(starlightcurves2, dtype = float)[:,1:]\n",
    "X8_test2 = np.array(starlightcurves3, dtype = float)[:,1:]\n",
    "X8_test = np.concatenate((X8_test1,X8_test2), axis = 0)\n",
    "y8_test1 = np.array(starlightcurves2, dtype=float)[:,0]\n",
    "y8_test2 = np.array(starlightcurves3, dtype=float)[:,0]\n",
    "y8_test = np.concatenate((y8_test1,y8_test2))\n",
    "\n",
    "\n",
    "twoleadECG = pd.read_csv('TwoLeadECG_Train.csv', header = None)\n",
    "twoleadECG2  = pd.read_csv('TwoLeadECG_Test.csv', header = None)\n",
    "\n",
    "\n",
    "X9_train = np.array(twoleadECG , dtype = float)[:,1:]\n",
    "X9_test = np.array(twoleadECG2 , dtype = float)[:,1:]\n",
    "y9_train = np.array(twoleadECG , dtype=float)[:,0]\n",
    "y9_test = np.array(twoleadECG2 , dtype=float)[:,0]\n",
    "\n",
    "yoga = pd.read_csv('Yoga_Train.csv', header = None)\n",
    "yoga2  = pd.read_csv('Yoga_Test.csv', header = None)\n",
    "\n",
    "\n",
    "X10_train = np.array(yoga , dtype = float)[:,1:]\n",
    "X10_test = np.array(yoga2 , dtype = float)[:,1:]\n",
    "y10_train = np.array(yoga , dtype=float)[:,0]\n",
    "y10_test = np.array(yoga2 , dtype=float)[:,0]\n",
    "\n",
    "y10_train[np.where(y10_train == 1)[0]] = -1\n",
    "y10_train[np.where(y10_train == 2)[0]] = 1\n",
    "\n",
    "\n",
    "EOGHorizontal = pd.read_csv('EOGHorizontal_Train.csv', header = None)\n",
    "EOGHorizontal2  = pd.read_csv('EOGHorizontal_Test.csv', header = None)\n",
    "\n",
    "\n",
    "X11_train = np.array(EOGHorizontal , dtype = float)[:,1:]\n",
    "X11_test = np.array(EOGHorizontal2 , dtype = float)[:,1:]\n",
    "y11_train = np.array(EOGHorizontal , dtype=float)[:,0]\n",
    "y11_test = np.array(EOGHorizontal2 , dtype=float)[:,0]\n",
    "\n",
    "\n",
    "\n",
    "CinECGTorso = pd.read_csv('CinECGTorso_Train.csv', header = None)\n",
    "CinECGTorso2  = pd.read_csv('CinECGTorso_Test.csv', header = None)\n",
    "\n",
    "\n",
    "X12_train = np.array(CinECGTorso , dtype = float)[:,1:]\n",
    "X12_test = np.array(CinECGTorso2 , dtype = float)[:,1:]\n",
    "y12_train = np.array(CinECGTorso , dtype=float)[:,0]\n",
    "y12_test = np.array(CinECGTorso2 , dtype=float)[:,0]\n",
    "\n",
    "ECG5000 = pd.read_csv('ECG5000_Train.csv', header = None)\n",
    "ECG50002  = pd.read_csv('ECG5000_Test.csv', header = None)\n",
    "\n",
    "\n",
    "X13_train = np.array(ECG5000 , dtype = float)[:,1:]\n",
    "X13_test = np.array(ECG50002 , dtype = float)[:,1:]\n",
    "y13_train = np.array(ECG5000 , dtype=float)[:,0]\n",
    "y13_test = np.array(ECG50002 , dtype=float)[:,0]\n",
    "\n",
    "\n",
    "l = [[X1_train, X1_test, y1_test], [X2_train, X2_test, y2_test], [X3_train, X3_test, y3_test],\n",
    "\t   [X4_train, X4_test, y4_test], [X5_train, X5_test, y5_test], [X6_train, X6_test, y6_test],\n",
    "\t   [X7_train, X7_test, y7_test], [X8_train, X8_test, y8_test], [X9_train, X9_test, y9_test],\n",
    "\t   [X10_train, X10_test, y10_test], [X11_train, X11_test, y11_test], [X12_train, X12_test, y12_test],\n",
    "\t   [X13_train, X13_test, y13_test]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FPCA on with preliminary filtering on all basis of wavelist  :\n",
    "\n",
    "### The next cell takes approximatively 1 hour of computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bench_FPCA_all(l):\n",
    "    np.random.seed(42)\n",
    "    liste = pywt.wavelist(kind='discrete')\n",
    "    predict_IF = []\n",
    "    predict_LOF = []\n",
    "    predict_OCSVM = []\n",
    "    for my_wave in liste:\n",
    "        A_raw = pywt.wavedec(np.array(l[0]),\n",
    "                         my_wave,\n",
    "                         mode=\"sym\")\n",
    "        A2_raw = pywt.wavedec(np.array(l[1]),\n",
    "                         my_wave,\n",
    "                         mode=\"sym\")\n",
    "        A = np.hstack(A_raw)\n",
    "        A2 = np.hstack(A2_raw)\n",
    "        K = 10\n",
    "        X_tilde = 1. / np.sqrt(l[0].shape[0]) * A\n",
    "        X2_tilde = 1. / np.sqrt(l[1].shape[0]) * A2\n",
    "        my_pca = PCA(n_components = K,\n",
    "                     whiten = True # For having projections with unit variance\n",
    "                    )\n",
    "        X_fpca = my_pca.fit_transform(X_tilde) # Matrix of coefficients\n",
    "        X2_fpca = my_pca.fit_transform(X2_tilde) \n",
    "        IF = IsolationForest(n_estimators=100, max_samples='auto',behaviour='new', contamination='auto')\n",
    "        IF.fit(X_fpca)\n",
    "        predict_1 = IF.decision_function(X2_fpca)\n",
    "        predict_IF.append(roc_auc_score(l[2], predict_1))\n",
    "        LOF = LocalOutlierFactor(n_neighbors=20 ,contamination='auto', novelty = True)\n",
    "        LOF.fit(X_fpca)\n",
    "        predict_2 = LOF.decision_function(X2_fpca)\n",
    "        predict_LOF.append(roc_auc_score(l[2], predict_2))\n",
    "        OC = OneClassSVM(kernel='rbf',gamma='scale')\n",
    "        OC.fit(X_fpca)\n",
    "        predict_3 = OC.decision_function(X2_fpca)\n",
    "        predict_OCSVM.append(roc_auc_score(l[2], predict_3))\n",
    "    return predict_IF, predict_LOF, predict_OCSVM\n",
    "\n",
    "if __name__ == '__main__': # excute on main process only\n",
    "    p = Pool(13)\n",
    "    result_FPCA_all = p.map(Bench_FPCA_all, l) \n",
    "\n",
    "# Results of Isolation Forest :\n",
    "A = np.zeros((106,13))\n",
    "# Results of Local Outlier Factor :\n",
    "B = np.zeros((106,13))\n",
    "# Results of One-class SVM :\n",
    "C = np.zeros((106,13))\n",
    "\n",
    "for i in range(13):\n",
    "    A[:,i] = result_FPCA_all[i][0]\n",
    "    B[:,i] = result_FPCA_all[i][1]\n",
    "    C[:,i] = result_FPCA_all[i][2]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
